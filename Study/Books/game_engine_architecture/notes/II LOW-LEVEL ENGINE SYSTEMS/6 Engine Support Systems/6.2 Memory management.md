## Affecting performance
- malloc and new are really **slow**
- if data is not presented in **small, contiguious blocks** it is inefficient
> Even the most efficient algorithm, coded with the utmost care, can be brought to its knees if the data upon which it operates is not laid out efficiently in memory.
## Optimization of dynamic memory allocation
Keep heap allocations to a minimum, and never allocate from the heap within a tight loop.
Providing custom allocator might be useful since it omits kernel calls.
### Stack allocator
In game engines used to load levels. Provide loading in stack-like fashion. Easy to implement
1. Allocate big chunk of memory (new, malloc or **global array of bytes**)
2. Store pointer to the top of the stack. All data below is used, all above is free.
3. Allocating moves pointer up.
4. Rolling should be performed to the point between two allocated blocks.
Example:
```
class StackAllocator
{
public:
	//stack marker: current top, 
	//you can only roll back to a marker, not to arbitrary locations
	typedef U32 Marker;
	
	//constructs with defined size
	explicit StackAllocator(U32 stackSize_bytes);

	 //allocates a new block of the given size from stack top
	 void* alloc(U32 size_bytes);

	//returns marker to current size top
	Marker getMarker();
	
	//rolls to previous marker
	void freeToMarker(Marker marker);

	//clears stack
	void clear();
}
```
Stack Allocator 
![[Pasted image 20250307230702.png]]
### Double-ended Stack Allocators. 
Might optimize memory management. In *Hydro Thunder* one side was used for level loading, and other for loading temporary assets, that were freed each frame.
**==First pointer->(BLOCK OF MEMORY)<-Second pointer==**
### Pool Allocators.
Those allocators work as follows:
preallocation of large block of memory, whose size is exact multiple of the size of the elements that will be allocated. A pool of 4x4 matrices would be multiple of 64 bytes - 16 elements per matrix times 4 for element.
**Allocations and frees are O(1)**.
We can store each free list "next" pointer in the memory allocated for objects. It works as long as elementSize >= sizeof(void*). If each element is smaller than a pointer, we can indices e.g. if we store 16 bit integers, we can use 16 bit indices as the next pointer in our linked list. Works as long as pool does not contain more than 2<sup>16</sup>.
### Aligned allocators.
Type of allocators which returns data aligned to some values.
On PS3, memory blocks that are to be transferred to an SPU via DMA controller, should be 128-byte aligned for maximum DMA throughput, meaning they can end with 0x00 or 0x80.
Relatively straightforward to implement:
**Allocate a bit more memory than requested**.
In most implementations, number of additional bytes is equal to alignment minus **one.**
Possible implementation:
```
//Shifts the given address upwards if/as necessary to
//ensure it is aligned to the given number of bytes
inline uintptr_t AlignAddress(uintptr_t addr, size_t align)
{
	const size_t mask = align - 1;
	assert((align & mask) == 0); //pwr of 2
	return (addr + mask) & ~mask
}

//Shifts the given pointer upwards if/as necessary to
//ensure it is aligned to the given number of bytes
template<typename T>
inline T* AlignPointer(T* ptr, size_t align)
{
	const uintptr_t addr = reinterpret_cast<uintptr_t>(ptr);
	const uintptr_t addrAligned = AlignAddress(addr, align);
	return reinterpret_cast<T*>(addrAligned);
}

//Aligned allocation function. IMPORTANT: 'align'
//must be power of 2
void* AllocAligned(size_t bytes, size_t align)
{
	size_t worstCaseBytes = bytes + align - 1;
	U8* pRawMem = new U8[worstCaseBytes];
	return AlignPointer(pRawMem, align);
}
```
For example, to align any address to a 16-byte boundary, we shift it up by 15 bytes and then mask off the N = log2 (16) = 4 least-significant bits.
```
addr = 40;
align = 16;
mask = 15;
(55) & ~(10000);
(110111) & (10000);
110000 = 48 -> aligned!
```
### Freeing aligned blocks.
To later free aligned blocks, we pass *shifted* address, but we have to free **original** address.
We can store it in the additional bytes from
`size_t worstCaseBytes = bytes + align - 1;`
formula.
Problem is, data might arrive aligned, so we will not have any additional bytes.
**SIMPLY,** lets allocate *L* additional bytes instead of *L - 1*.
Modified function
```
void* AllocAligned(size_t bytes, size_t align)
{
	//Allocate L not L - 1
	size_t actualBytes = bytes + align;
	//Allocate unaligned block
	U8* pRawMem = new U8[actualBytes];
	//Align the block
	//if no alignment needed
	//shift up with full 'align'
	U8* pAlignedMem = AlignPointer(pRawMem, align);
	if(pAlignedMem == pRawMem)
		pAlignedMem += align
	//Determine shift and store it (up to 256 value)
	ptrdiff_t shift = pAlignedMem - pRawMem;
	pAlignedMem[-1] = static_cast<U8>(shift & 0xff);
	return pAlignedMem;
}

void FreeAligned(void* pMem)
{
	if(pMem)
	{
		U8* pAlignedMem = reinterpret_cast<U8*>(pMem);
		ptrdiff_t shift = pAlignedMem[-1];
		if(shift == 0)
			shift = 256;
		U8* pRawMem = pAlignedMem - shift;
		delete[] pRawMem;
 	}
}
```
### Single-Frame and Double-Buffered Memory Allocators.
Most game engine use allocators which discards data each frame or use it in next frame and then discards.
#### Single-Frame Allocators
Those are allocators which keep data only for one frame. With this pattern Stack allocator is commonly used. 
```
StackAllocator g_singleFrameAllocator;
while(true)
{
	g_singleFrameAllocator.clear();
	//no need to free allocated data, just make sure to use it in 1 frame
	void* p = g_singleFrameAllocator.alloc(nBytes);
}
```
**Pros:**
- blazingly fast
**Cons:**
- requires reasonable level of discipline on the part of the programmer
> Programmers must never cache a pointer to a single-frame memory block across the frame boundary!
#### Double-Buffered Allocators
Allows data allocated in frame *i* to be used in the frame *i+1*.
To construct, provide two single-frame stack allocators of equal size and ping-pong between them.
```
class DoubleBufferedAllocator
{
	U32 m_curStack;
	StackAllocator m_stack[2];
public:
	void swapBuffers()
	{
		m_curStack = (U32)!m_curStack;
	}
	void clearCurrentBuffer()
	{
		m_stack[m_currStack].clear();
	}
	void* alloc(U32 nBytes)
	{
		return m_stack[m_curStack].alloc(nBytes);
	}
}

DoubleBufferedAllocator g_doubleBufAllocator;

while(true)
{
	g_singleFrameAllocator.clear();
	g_doubleBufAllocator.swapBuffers();
	g_doubleBufAllocator.clearCurrentBuffer();
	//allocate out of the current buffer
	//data will be available this and next frame
	//does not needs to be freed
	void* p = g_doubleBufAllocator.alloc(nBytes);
}
```
## Memory fragmentation
How does it work?
![[Pasted image 20250309212452.png]]
After many allocations and deallocations, there are a lot of holes.
We can introduce support of *virtual memory*. Virtual system maps discontiguous blocks of physical memory known as pages into a *virtual address space*, where pages appear for application to be contiguous. 
### Avoiding fragmentation with Stack and Pool allocators.
Using those type of allocators prevent fragmentation. Why?
- Stack allocator always has to be allocated on the top of the previous allocations, and freeing also can not be out of order.
- Pool allocator is also useful for this, because there may be out of order deallocation and holes in the allocated memory, but since all blocks are the same size, allocation will never fail if there is any free space.
### Defragmentation and Relocation.
One simple algorithm of this behavior is to search for the first hole and then take the allocated block immediately above the hole and shift it down to the start of the hole. This has the effect of bubbling up the hole to the higher memory address.
If this process is repeated, at the end all the allocated blocks will occupy a contiguous region of memory. 
**What is tricky is accounting for the fact that weâ€™re moving allocated blocks of memory around. If anyone has a pointer into one of these allocated blocks, then moving the block will invalidate the pointer.**
To prevent this, we need to *relocate* the pointers.
There is no way to keep track of address where each pointer is pointing to, thus programmer should abandon pointers in favor of *smart pointers* or *handles*.
Smart pointer is a class that contains pointer. It can also handle memory relocation properly. One approach is to arrange all smart pointers into a global linked list. When a block of memory is shifted within the heap, list can be scanned and each pointer that points to this block can be adjusted.
A handle is usually implemented as an index into a non-relocatable table, which itself contains the pointers. When an allocated block is shifted in memory, the handle table can be scanned and all relevant pointers found and updated.
Problem **occurs** when some of the blocks will be non-relocatable. If their number and size will be kept small, this mechanism will still perform well.
#### Amortizing Defragmentation Class.
Since dynamically allocated objects are usually small, and defragmentation could be slow process, we can break into lot of frames. As long as defragmentation shifts are faster than allocations and deallocations, this should not be a problem.

**END OF THE CHAPTERS**