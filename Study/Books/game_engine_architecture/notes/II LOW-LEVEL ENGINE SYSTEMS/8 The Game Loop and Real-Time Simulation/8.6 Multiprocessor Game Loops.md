How to apply concurrent mechanisms to game engine's game loop.
# Task decomposition
To take advantage of parallel computing, we have to decompose tasks to execute each of them i parallel. 
There are many ways to decompose, but most of them will be in 2 categories: *task parallelism* and *data parallelism*.
First one is when number of tasks have to be done and we opt to do them in parallel across multiple cores.
Data parallelism is when a single computation needs to be performed repeatedly on a large number of data elements. GPU is best example.
**Different ways to subdivide the work that is done by the game loop.**
# One Thread per Subsystem
Assign engine subsystems to separate threads.
For example, the rendering engine, the collision and physics simulation, the animation pipeline, and the audio engine could each be assigned to its own thread.
Main thread would handle the control and synchronization.
This is example of *task parallelism.*
**There are a number of problems with the simple approach of assigning each engine subsystem to its own thread.**
First of all, number of subsystems will not match cores.
Another problem is that each subsystem requires different amount of processing each frame.
Another issue is that some subsystems depend on data produced by others.
**For example, the rendering and audio subsystems cannot start doing their work for frame N until the animation, collision and physics systems have completed their work for frame N.**
# Scatter/Gather
Many tasks are data intensive. For example, we may need to process a large number of ray cast requests, blend together a large batch of animation poses, or calculate world-space matrices for every object in a massive interactive scene.
One way to take advantage of parallel computing hardware is to perform those tasks with divide-and-conquer approach.
![[Pasted image 20250327193928.png]]
This is *data parallelism.*
## Scatter/Gather in Game Loop
Given a dataset containing N data items that require processing, the master thread would divide the work into m batches, each containing roughly N/m elements. (The value of m would probably be determined based on the number of available cores in the system, although this may not be the case if, for example, we wish to leave some cores free for other work.)
Then, m workers would be spawned.
Each worker thread might update the data items in-place, or (usually better) it might produce output data into a separate preallocated buffer (one per worker thread).
Main thread might perform some useful things while waiting for result
## SIMD for Scatter/Gather
SIMD could be used in lieu of thread-based scatter/gather, but it would likely be used in conjunction with it (with each worker thread utilizing vectorization internally to perform its work)
## More efficient Scatter/Gather
Spawning threads is expensive.
We could mitigate the costs of spawning threads by using of a pool of prespawned threads.
Really, what we want is a general-purpose system for executing units of work concurrently, across the available cores on our target hardware.
# Job system
General-purpose system for executing arbitrary units of work, typically called jobs, across multiple cores.
The job system maintains a queue of submitted jobs, and it schedules those jobs across the available cores, either by submitting them to be executed by worker threads in a thread pool, or by some other means.
## Typical Job system interface
Looks similar to threading library API.
Usually there is a function to *kick* a job (spawning), a function that allows one job to wait for another and perhaps a way to terminate job early.
Job system has to provide spin locks of mutexes of some kind for performing critical concurrent operations in an *atomic manner*. It may also provide facilities for putting jobs to sleep and waking them back up, via condition variables or some similar mechanism.
![[Pasted image 20250327195136.png]]
To kick a job, we need to tell what job to perform and how to do it. This information is passed to `KickJob()` via small structure - job declaration.
```
namespace job {
	typedef void EntryPoint(uintptr_t param);
	enum class Priority
	{
		LOW, NORMAL, HIGH, CRITICAL
	};
	struct Counter ... ;
	Counter* AllocCounter();
	void FreeCounter(Counter* pCounter);
	struct Declaration
	{
		EntryPoint* entryPoint;
		uintptr_t param;
		Priority priority;
		Counter* counter;
	};
	void KickJob(const Declaration& decl);
	void KickJobs(int count, const Declaration aDecl[]);
	void WaitForCounter(Counter* _counter);
	void KickJobAndWait(const Declaration& decl);
	void KickJobsAndWait(int count, const Declaration aDecl[]);
}
```